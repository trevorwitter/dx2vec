{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82067bc4-2e04-4092-acfe-d58b1ebf4c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12fe11510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc34072-2142-4241-81c2-9d8a91ca15da",
   "metadata": {},
   "source": [
    "## Get diagosis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f8691f-2c0c-45fa-b064-5f3658db3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_op_claims(sample=1):\n",
    "    \"\"\"Returns all outpatient claims for selected sample\"\"\"\n",
    "    df = pd.read_csv(f'https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/Downloads/DE1_0_2008_to_2010_Outpatient_Claims_Sample_{sample}.zip',\n",
    "                     usecols=['DESYNPUF_ID','CLM_ID','CLM_FROM_DT','PRVDR_NUM','CLM_PMT_AMT',\n",
    "                               'ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3', 'ICD9_DGNS_CD_4',\n",
    "                               'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7', 'ICD9_DGNS_CD_8',\n",
    "                               'ICD9_DGNS_CD_9', 'ICD9_DGNS_CD_10', 'ICD9_PRCDR_CD_1',\n",
    "                               'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3', 'ICD9_PRCDR_CD_4',\n",
    "                               'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6', 'ADMTNG_ICD9_DGNS_CD', 'HCPCS_CD_1',\n",
    "                               'HCPCS_CD_2', 'HCPCS_CD_3', 'HCPCS_CD_4', 'HCPCS_CD_5', 'HCPCS_CD_6',\n",
    "                               'HCPCS_CD_7', 'HCPCS_CD_8', 'HCPCS_CD_9', 'HCPCS_CD_10', 'HCPCS_CD_11',\n",
    "                               'HCPCS_CD_12', 'HCPCS_CD_13', 'HCPCS_CD_14', 'HCPCS_CD_15',\n",
    "                               'HCPCS_CD_16', 'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19',\n",
    "                               'HCPCS_CD_20', 'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23',\n",
    "                               'HCPCS_CD_24', 'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27',\n",
    "                               'HCPCS_CD_28', 'HCPCS_CD_29', 'HCPCS_CD_30', 'HCPCS_CD_31',\n",
    "                               'HCPCS_CD_32', 'HCPCS_CD_33', 'HCPCS_CD_34', 'HCPCS_CD_35',\n",
    "                               'HCPCS_CD_36', 'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39',\n",
    "                               'HCPCS_CD_40', 'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43',\n",
    "                               'HCPCS_CD_44', 'HCPCS_CD_45'],\n",
    "                     dtype={'CLM_ID':int,'CLM_PMT_AMT':int},\n",
    "                     compression='zip',\n",
    "                     engine='c',\n",
    "                     parse_dates=['CLM_FROM_DT']\n",
    "                    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6cb23b-8f71-4af5-be14-0f6eca3a4a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/4jttxk_j59ngw4ck3xdp25th0000gn/T/ipykernel_14892/2871165091.py:3: DtypeWarning: Columns (21,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/Downloads/DE1_0_2008_to_2010_Outpatient_Claims_Sample_{sample}.zip',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 680 ms, total: 3.41 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(790790, 67)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = get_sample_op_claims(sample=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2c5980-231b-4fbc-a146-1b8a5cbbd367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.27 claims per member on average\n"
     ]
    }
   ],
   "source": [
    "claims_per_member = round(len(df)/len(df['DESYNPUF_ID'].unique()),2)\n",
    "print(f\"{claims_per_member} claims per member on average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ca1238-efa4-4bdd-a5e4-82fd8c6a5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dx_df(df):\n",
    "    df_out = df[['DESYNPUF_ID','CLM_FROM_DT',\n",
    "                 #'ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3', 'ICD9_DGNS_CD_4',\n",
    "                 #'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7', 'ICD9_DGNS_CD_8',\n",
    "                 #'ICD9_DGNS_CD_9', 'ICD9_DGNS_CD_10', \n",
    "                 'ADMTNG_ICD9_DGNS_CD',]\n",
    "               ].melt(id_vars=['DESYNPUF_ID','CLM_FROM_DT'],\n",
    "                      value_name='dx'\n",
    "                     ).drop('variable',axis=1)\n",
    "    df_out = df_out[df_out['dx'].isna()==False]\n",
    "    df_out = df_out.drop_duplicates(['DESYNPUF_ID','CLM_FROM_DT','dx']).reset_index(drop=True)\n",
    "    return df_out\n",
    "\n",
    "def get_prcdr_df(df):\n",
    "    df_out = df[['DESYNPUF_ID','CLM_FROM_DT', 'ICD9_PRCDR_CD_1',\n",
    "                 'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3', 'ICD9_PRCDR_CD_4',\n",
    "                 'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6', \n",
    "              ]\n",
    "               ].melt(id_vars=['DESYNPUF_ID','CLM_FROM_DT'],\n",
    "                      value_name='prcdr'\n",
    "                     ).drop('variable',axis=1)\n",
    "    df_out = df_out[df_out['prcdr'].isna()==False]\n",
    "    df_out = df_out.drop_duplicates(['DESYNPUF_ID','CLM_FROM_DT','prcdr']).reset_index(drop=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6043a167-9037-45b4-aaf9-e7b401f5fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df = get_dx_df(df)\n",
    "prcdr_df = get_prcdr_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d80b1a4-216f-4d84-8245-b57036552dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194463, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815405fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prcdr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a51258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESYNPUF_ID</th>\n",
       "      <th>CLM_FROM_DT</th>\n",
       "      <th>prcdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0071E2E641B73233</td>\n",
       "      <td>2008-03-12</td>\n",
       "      <td>3995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0073EAD53F4BBC1C</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>7971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0076A3B03FA644E9</td>\n",
       "      <td>2010-04-07</td>\n",
       "      <td>3324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00FDFA655DD462F8</td>\n",
       "      <td>2008-02-06</td>\n",
       "      <td>9952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013C8094EEB51A84</td>\n",
       "      <td>2008-01-18</td>\n",
       "      <td>9462.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DESYNPUF_ID CLM_FROM_DT   prcdr\n",
       "0  0071E2E641B73233  2008-03-12  3995.0\n",
       "1  0073EAD53F4BBC1C  2010-08-21  7971.0\n",
       "2  0076A3B03FA644E9  2010-04-07  3324.0\n",
       "3  00FDFA655DD462F8  2008-02-06  9952.0\n",
       "4  013C8094EEB51A84  2008-01-18  9462.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prcdr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86a9647-d6eb-4251-a672-6e94e5339782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dx_df = dx_df.head(2000)\n",
    "dx_df = dx_df.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8bd4fb-4bd9-41bf-b29c-8c94e5e5b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESYNPUF_ID</th>\n",
       "      <th>CLM_FROM_DT</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00013D2EFD8E45D1</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>V5841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>2009-06-02</td>\n",
       "      <td>V5832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001FDD721E223DC</td>\n",
       "      <td>2009-10-11</td>\n",
       "      <td>78943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00024B3D2352D2D0</td>\n",
       "      <td>2008-07-12</td>\n",
       "      <td>6009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DESYNPUF_ID CLM_FROM_DT     dx\n",
       "0  00013D2EFD8E45D1  2008-09-04  V5841\n",
       "1  00016F745862898F  2009-06-02  V5832\n",
       "2  00016F745862898F  2009-06-23   9594\n",
       "3  0001FDD721E223DC  2009-10-11  78943\n",
       "4  00024B3D2352D2D0  2008-07-12   6009"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965bac3f-a54d-4dbd-b8e1-7536c971fd74",
   "metadata": {},
   "source": [
    "# Dx dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c07605c-b178-4429-8041-f5ed3042016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(dx_df['dx'])\n",
    "vocab.add('[blank]')\n",
    "dx_to_ix = {dx: i for i, dx in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8446a7-26c4-4fdb-87b6-a95f06dead05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b4e863-32da-4894-a3e3-85cf35fcf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df['dx'] = [dx_to_ix[x] for x in dx_df['dx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f59d945e-b8d3-4195-93b6-fac6cab40f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DXDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, ID_col, context_size, dx_to_ix, mode='CBOW'):\n",
    "        self.data = df\n",
    "        self.ID_col = ID_col\n",
    "        self.context_size=context_size\n",
    "        self.dx_to_ix = dx_to_ix\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        member = dx_df[self.ID_col].iloc[idx]\n",
    "        df1 = dx_df[dx_df[self.ID_col] == member].copy()\n",
    "        self.df1 = df1\n",
    "        \n",
    "        if self.mode == 'CBOW':\n",
    "            if idx >= df1.index.min():\n",
    "                start = idx - self.context_size//2\n",
    "            else:\n",
    "                start = df1.index.min()\n",
    "            end = idx + self.context_size//2\n",
    "            \n",
    "            ngrams_pre = [x for x in df1['dx'].loc[start:(idx-1)]]\n",
    "            ngrams_post = [x for x in df1['dx'].loc[idx+1:end]]\n",
    "            ngrams_pre.extend(ngrams_post)\n",
    "            \n",
    "            ngrams = [ngrams_pre,\n",
    "                      df1['dx'].loc[idx]\n",
    "                     ]\n",
    "        elif self.mode == 'lead':\n",
    "            if idx >= df1.index.min():\n",
    "                start = idx - self.context_size\n",
    "            else:\n",
    "                start = df1.index.min()\n",
    "            \n",
    "            ngrams = [[x for x in df1['dx'].loc[start:(idx-1)]],\n",
    "                      df1['dx'].loc[idx]\n",
    "                     ]\n",
    "            \n",
    "            \n",
    "        if len(ngrams[0]) == 0:\n",
    "            ngrams[0] = [dx_to_ix['[blank]'] for x in range(self.context_size)]\n",
    "        elif len(ngrams[0]) < self.context_size:\n",
    "            size_ = self.context_size - len(ngrams[0])\n",
    "            for x in range(size_):\n",
    "                ngrams[0].insert(0, dx_to_ix['[blank]'])\n",
    "        else:\n",
    "            pass\n",
    "        ngrams[0] = torch.tensor(ngrams[0]).unsqueeze(0)\n",
    "        ngrams[1] = torch.tensor(ngrams[1])\n",
    "        return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cf4a3-57ce-455e-98f9-900d0f5cdf9f",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b29312-9957-4fa5-bcbe-03fbda11d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramICDModeler(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramICDModeler, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        embeds = self.embeddings(inputs).view(batch_size, 1, self.context_size*self.embedding_dim)\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=0).view(batch_size, self.vocab_size)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cae89-6c12-4141-9961-80bb96b33f19",
   "metadata": {},
   "source": [
    "## Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c3dd0a-cbc9-41bb-a523-8c245358c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, training_generator, model, loss_function, device, verbose=True):\n",
    "    losses = []\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(training_generator):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss)\n",
    "        if verbose == True:\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"Epoch: {epoch} --- Loss: {round(total_loss, 2)}\")\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d96ac9-a10c-411d-98e9-c40b71a75dbe",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067b151b-fadf-4bed-b328-463d3a4cb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4323021-85ee-4c37-aede-655c5976011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "CONTEXT_SIZE = 10\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "#model = NGramICDModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
    "model = NGramICDModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e11a679-1e58-4400-85c9-f1f9c454ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DXDataset(df=dx_df,\n",
    "                 ID_col='DESYNPUF_ID',\n",
    "                 context_size=CONTEXT_SIZE,\n",
    "                 dx_to_ix=dx_to_ix,\n",
    "                 mode='CBOW')\n",
    "\n",
    "training_generator = torch.utils.data.DataLoader(data,\n",
    "                                                 batch_size=128,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_workers=8,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc87747-5b02-48a3-9c4f-4302459d3d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/twitter/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/twitter/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'DXDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(epochs, training_generator, model, loss_function, device, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(training_generator):\n\u001b[1;32m      7\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m      8\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_torch/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, losses = training_loop(10,\n",
    "                              training_generator,\n",
    "                              model,\n",
    "                              loss_function,\n",
    "                              device=device,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058027ac-7a02-4068-bf05-139abd974004",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68179314-8829-4c7a-8f50-4658ab6a28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/test_icd_cbow_{EMBEDDING_DIM}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9f2bc-4c45-471f-99f8-1e4308a818db",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- May want to incorporate parallelism - can [DataParallel](https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html#part-of-the-model-on-cpu-and-part-on-the-gpu) allow multi-core parallel training on single GPU? or only multiple GPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610746a-1ff9-4d0d-bb9a-84f66afb8660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
